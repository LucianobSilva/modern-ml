{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367a8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "read-data",
   "metadata": {},
   "source": [
    "### Read the parquet file located at `./week_1/data/processed/full_churn_data_with_target.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5286530 entries, 0 to 5286529\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   Id                        int64         \n",
      " 1   customer_id               int64         \n",
      " 2   interest_rate             float64       \n",
      " 3   name                      object        \n",
      " 4   country                   object        \n",
      " 5   date_of_birth             object        \n",
      " 6   address                   object        \n",
      " 7   date                      datetime64[ns]\n",
      " 8   atm_transfer_in           int64         \n",
      " 9   atm_transfer_out          int64         \n",
      " 10  bank_transfer_in          int64         \n",
      " 11  bank_transfer_out         int64         \n",
      " 12  crypto_in                 int64         \n",
      " 13  crypto_out                int64         \n",
      " 14  bank_transfer_in_volume   float64       \n",
      " 15  bank_transfer_out_volume  float64       \n",
      " 16  crypto_in_volume          float64       \n",
      " 17  crypto_out_volume         float64       \n",
      " 18  complaints                int64         \n",
      " 19  touchpoints               object        \n",
      " 20  csat_scores               object        \n",
      " 21  tenure                    int64         \n",
      " 22  from_competitor           bool          \n",
      " 23  job                       object        \n",
      " 24  churn_due_to_fraud        bool          \n",
      " 25  model_predicted_fraud     bool          \n",
      " 26  Usage                     object        \n",
      " 27  churn                     int64         \n",
      " 28  next_date                 datetime64[ns]\n",
      " 29  days_diff                 float64       \n",
      " 30  split                     object        \n",
      "dtypes: bool(3), datetime64[ns](2), float64(6), int64(11), object(9)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('./week_1/data/processed/full_churn_data_with_target.parquet')\n",
    "df.reset_index(drop=False, inplace=True) \n",
    "df.sort_values(by=['customer_id', 'date'], ascending=True, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-engineering",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402657cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Touchpoints nested list to individual count columns\n",
    "\n",
    "# 1. Explode the touchpoints list column to transform each channel into its own row\n",
    "exploded_df = df.explode('touchpoints')\n",
    "\n",
    "# 2. Count the occurrences of each channel per original row\n",
    "counts = (exploded_df.groupby([exploded_df.index, 'touchpoints'])\n",
    "                     .size()\n",
    "                     .unstack(fill_value=0))\n",
    "\n",
    "exploded_df = None\n",
    "\n",
    "# 3. Ensure all possible columns exist (email, appointment, phone, whatsapp)\n",
    "for col in ['email', 'appointment', 'phone', 'whatsapp']:\n",
    "    if col not in counts.columns:\n",
    "        counts[col] = 0\n",
    "\n",
    "# 4. Merge these counts back into the original DataFrame\n",
    "df = df.join(counts, how='left').fillna(0)\n",
    "counts = None\n",
    "\n",
    "# 5. Convert counts to integer type\n",
    "df[['email', 'appointment', 'phone', 'whatsapp']] = (\n",
    "    df[['email', 'appointment', 'phone', 'whatsapp']].astype(int)\n",
    ")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "base-churn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base churn\n",
    "df['days_between'] = df.groupby('customer_id')['date'].diff().dt.days.fillna(0)\n",
    "df['customer_age'] = (df['date'] - pd.to_datetime(df['date_of_birth'])).dt.days / 365.25\n",
    "df['from_competitor'] = df['from_competitor'].astype(int)\n",
    "df['churn_due_to_fraud'] = df['churn_due_to_fraud'].astype(int)\n",
    "df['atm_transfer_in'] = df['atm_transfer_in']\n",
    "df['atm_transfer_out'] = df['atm_transfer_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "window-features",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lifetime Window features...\n",
      "Adding window features for 10D ...\n",
      "Adding window features for 90D ...\n",
      "Adding window features for 180D ...\n",
      "Adding window features for 365D ...\n",
      "Adding window features for 450D ...\n"
     ]
    }
   ],
   "source": [
    "# Window features\n",
    "print('Lifetime Window features...')\n",
    "df['prior_emails'] = df.groupby('customer_id')['email'].cumsum().values\n",
    "df['prior_appointments'] = df.groupby('customer_id')['appointment'].cumsum().values\n",
    "df['prior_phones'] = df.groupby('customer_id')['phone'].cumsum().values\n",
    "df['prior_whatsapps'] = df.groupby('customer_id')['whatsapp'].cumsum().values\n",
    "\n",
    "df['prior_count'] = df.groupby('customer_id').cumcount() + 1\n",
    "df['prior_bank_balance'] = df.groupby('customer_id')['bank_transfer_in_volume'].cumsum().values - df.groupby('customer_id')['bank_transfer_out_volume'].cumsum().values\n",
    "df['prior_crypto_balance'] = df.groupby('customer_id')['crypto_in_volume'].cumsum().values - df.groupby('customer_id')['crypto_out_volume'].cumsum().values\n",
    "df['prior_mean_days_between'] = df.groupby('customer_id')['days_between'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df['prior_min_days_between'] = df.groupby('customer_id')['days_between'].expanding().min().reset_index(level=0, drop=True)\n",
    "df['prior_max_days_between'] = df.groupby('customer_id')['days_between'].expanding().max().reset_index(level=0, drop=True)\n",
    "df['prior_mean_bank_transfer_in'] = df.groupby('customer_id')['bank_transfer_in'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df['prior_mean_bank_transfer_out'] = df.groupby('customer_id')['bank_transfer_out'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df['prior_mean_crypto_in'] = df.groupby('customer_id')['crypto_in'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df['prior_mean_crypto_out'] = df.groupby('customer_id')['crypto_out'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df['prior_mean_bank_transfer_in_volume'] = df.groupby('customer_id')['bank_transfer_in_volume'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df['prior_mean_bank_transfer_out_volume'] = df.groupby('customer_id')['bank_transfer_out_volume'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df['prior_mean_crypto_in_volume'] = df.groupby('customer_id')['crypto_in_volume'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df['prior_mean_crypto_out_volume'] = df.groupby('customer_id')['crypto_out_volume'].expanding().mean().reset_index(level=0, drop=True)\n",
    "\n",
    "def add_window_features(df, window_size=''):\n",
    "    print('Adding window features for', window_size, '...')\n",
    "    df[f'prior_{window_size}_count'] = df.groupby('customer_id').rolling(window_size, on='date')['date'].count().values\n",
    "    df[f'prior_{window_size}_mean_days_between'] = df.groupby('customer_id').rolling(window_size, on='date')['days_between'].mean().values\n",
    "    df[f'prior_{window_size}_max_days_between'] = df.groupby('customer_id').rolling(window_size, on='date')['days_between'].max().values\n",
    "    df[f'prior_{window_size}_min_days_between'] = df.groupby('customer_id').rolling(window_size, on='date')['days_between'].min().values\n",
    "    df[f'prior_{window_size}_mean_bank_transfer_in'] = df.groupby('customer_id').rolling(window_size, on='date')['bank_transfer_in'].mean().values\n",
    "    df[f'prior_{window_size}_mean_bank_transfer_out'] = df.groupby('customer_id').rolling(window_size, on='date')['bank_transfer_out'].mean().values\n",
    "    df[f'prior_{window_size}_mean_crypto_in'] = df.groupby('customer_id').rolling(window_size, on='date')['crypto_in'].mean().values\n",
    "    df[f'prior_{window_size}_mean_crypto_out'] = df.groupby('customer_id').rolling(window_size, on='date')['crypto_out'].mean().values\n",
    "    df[f'prior_{window_size}_mean_bank_transfer_in_volume'] = df.groupby('customer_id').rolling(window_size, on='date')['bank_transfer_in_volume'].mean().values\n",
    "    df[f'prior_{window_size}_mean_bank_transfer_out_volume'] = df.groupby('customer_id').rolling(window_size, on='date')['bank_transfer_out_volume'].mean().values\n",
    "    df[f'prior_{window_size}_mean_crypto_in_volume'] = df.groupby('customer_id').rolling(window_size, on='date')['crypto_in_volume'].mean().values\n",
    "    df[f'prior_{window_size}_mean_crypto_out_volume'] = df.groupby('customer_id').rolling(window_size, on='date')['crypto_out_volume'].mean().values\n",
    "\n",
    "# Last 10 days\n",
    "add_window_features(df, '10D')\n",
    "\n",
    "# Last 90 days\n",
    "add_window_features(df, '90D')\n",
    "\n",
    "# Last 180 days\n",
    "add_window_features(df, '180D')\n",
    "\n",
    "# Last 365 days\n",
    "add_window_features(df, '365D')\n",
    "\n",
    "# Last 365 days\n",
    "add_window_features(df, '450D')\n",
    "\n",
    "# This week volume\n",
    "df.sort_values(by=['country', 'date'], ascending=True, inplace=True)\n",
    "df['this_week_bank_volume'] = df.groupby('customer_id').rolling('7D', on='date')['bank_transfer_in_volume'].sum().values - \\\n",
    "                         df.groupby('customer_id').rolling('7D', on='date')['bank_transfer_out_volume'].sum().values\n",
    "\n",
    "df['this_week_crypto_volume'] = df.groupby('customer_id').rolling('7D', on='date')['crypto_in_volume'].sum().values - \\\n",
    "                         df.groupby('customer_id').rolling('7D', on='date')['crypto_out_volume'].sum().values\n",
    "\n",
    "#df['this_week_customer_count_by_country'] = df.groupby('country').rolling('7D', on='date')['customer_id'].nunique().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed95aef4",
   "metadata": {},
   "source": [
    "### Defining diferent targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ffbde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 365 days of inactivity\n",
    "df['churn_365'] = 0\n",
    "df.loc[df['days_diff'] >= 365, 'churn_365'] = 1\n",
    "\n",
    "#420 days of inactivity\n",
    "df['churn_420'] = 0\n",
    "df.loc[df['days_diff'] >= 420, 'churn_420'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1de8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/kk2lyyc1509_l0ltgwm_19y40000gq/T/ipykernel_11068/3564919720.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.churn_18_months.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#All customers with a last activity date over a 18 months ago (reference date 2023-12-31).\n",
    "\n",
    "'''\n",
    "Verify this:\n",
    "\n",
    "We're never very confident in our prediction at the point of churn.\n",
    "\n",
    "We're asking a very hard question - is this transaction the last? Rather than asking has this customer churned after 100 days of inactivity have passed.\n",
    "\n",
    "(Of the 2270378 in the train data, only 9820 are \"final transactions\", ~0.43%)\n",
    "'''\n",
    "\n",
    "churned_customers = df[df.date < '2024-01-01'].groupby('customer_id')['date'].max().reset_index()\n",
    "churned_customers = churned_customers[churned_customers.date < '2022-06-01']\n",
    "churned_customers.columns = ['customer_id', 'churn_date']\n",
    "churned_customers['churn_18_months'] = 1\n",
    "\n",
    "df = pd.merge(df, churned_customers, how='left', left_on=['customer_id', 'date'], right_on=['customer_id', 'churn_date'])\n",
    "df.churn_18_months.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f821e8",
   "metadata": {},
   "source": [
    "### Saving the processed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ddc29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_features_list = ['Id', 'customer_id','name','date_of_birth','address','date','touchpoints','csat_scores','Usage','churn','next_date','days_diff','split','churn_365','churn_420','churn_date','churn_18_months']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list(df.drop(columns=non_features_list).columns)\n",
    "with open('./week_1/data/processed/final_features_list.json', 'w') as f:\n",
    "    json.dump(features_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "661540c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/02/kk2lyyc1509_l0ltgwm_19y40000gq/T/ipykernel_11068/2335050495.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df.Usage.replace(0, 'Public', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.sort_values(by=['Id'], ascending=True, inplace=True)\n",
    "df.Usage.replace(0, 'Public', inplace=True)\n",
    "df.to_parquet('./week_1/data/processed/feature_engineering_dataset.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
